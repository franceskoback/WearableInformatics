{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MDH-0806-2798', '2023-05-18', '73', '10206', '6.95']\n",
      "['MDH-0806-2798', '2023-05-19', '73', '13133', '6.333333333333333']\n",
      "['MDH-0806-2798', '2023-05-20', '73', '22670', '7.283333333333333']\n",
      "['MDH-0806-2798', '2023-05-21', '73', '28489', '6.533333333333333']\n",
      "['MDH-0806-2798', '2023-05-22', '73', '8503', '7.416666666666667']\n",
      "['MDH-0806-2798', '2023-05-23', '75', '12609', '7.233333333333333']\n",
      "['MDH-0806-2798', '2023-05-24', '77', '10462', '5.783333333333333']\n",
      "['MDH-0806-2798', '2023-05-25', '78', '14245', '6.383333333333334']\n",
      "['MDH-9789-3303', '2023-05-25', '42', '4500', '6.1']\n",
      "['MDH-9789-3303', '2023-05-25', '42', '4500', None]\n",
      "['MDH-0806-2798', '2023-05-26', '79', '133', '6.7']\n",
      "['MDH-9789-3303', '2023-05-26', '53', '3830', None]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Define the directory containing the data folders\n",
    "data_directory = \"/Users/franceskoback/Downloads/RK.E0CC9B64.Wearable Wellness_20230515-20230516\"\n",
    "data_directory = \"/Users/franceskoback/Downloads/RK.E0CC9B64.Wearable Wellness_20230522-20230523\"\n",
    "data_directory = \"/Users/franceskoback/Downloads/RK.E0CC9B64.Wearable Wellness_20230527-20230528\"\n",
    "data_directory = \"/Users/franceskoback/Downloads/RK.E0CC9B64.Wearable Wellness_20230526-20230527\"\n",
    "\n",
    "# Define the output file path for the aggregate CSV\n",
    "output_file = \"aggregate.csv\"\n",
    "\n",
    "# Define the columns to extract from each device's CSV\n",
    "columns = [\"ParticipantIdentifier\", \"Date\", \"RestingHeartRate\", \"Steps\", \"Sleep\"]\n",
    "\n",
    "# Initialize the aggregate data dictionary\n",
    "aggregate_data = []\n",
    "\n",
    "# Iterate over the data folders\n",
    "csv_file = [file for file in os.listdir(data_directory) if file.startswith(\"AllParticipants\") and file.endswith(\".csv\")]\n",
    "csv_file = os.path.join(data_directory, csv_file[0])\n",
    "\n",
    "with open(csv_file, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    header_row = next(reader)\n",
    "    header_row = [column.strip('\\ufeff') for column in header_row]\n",
    "    participant_identifier_index = header_row.index(\"ParticipantIdentifier\")\n",
    "    secondary_identifier_index = header_row.index(\"SecondaryIdentifier\")\n",
    "\n",
    "    for row in reader:\n",
    "        participant_identifier = row[participant_identifier_index]\n",
    "        device_type = row[secondary_identifier_index]\n",
    "\n",
    "        if device_type:\n",
    "            participant_date = row[1].split(\"T\")[0]  # Extract the date portion\n",
    "\n",
    "        if device_type and device_type.startswith(\"Apple\"):\n",
    "            # Search for resting heart rate CSV\n",
    "            resting_heart_rate_file = [file for file in os.listdir(data_directory) if\n",
    "                                       file.startswith(\"HealthKitV2Samples_RestingHeartRate_\") and file.endswith(\".csv\")]\n",
    "            if resting_heart_rate_file:\n",
    "                resting_heart_rate_file = os.path.join(data_directory, resting_heart_rate_file[0])\n",
    "                with open(resting_heart_rate_file, \"r\") as resting_hr_csv:\n",
    "                    resting_hr_reader = csv.reader(resting_hr_csv)\n",
    "                    next(resting_hr_reader)  # Skip the header row\n",
    "                    resting_heart_rate_date = None  # Initialize the resting heart rate date\n",
    "                    for hr_row in resting_hr_reader:\n",
    "                        if hr_row[1] == participant_identifier:\n",
    "                            resting_heart_rate = hr_row[4]\n",
    "                            resting_heart_rate_date = hr_row[3].split(\"T\")[0]  # Extract the date portion\n",
    "                            break\n",
    "\n",
    "                # Check if resting heart rate data is found\n",
    "                if resting_heart_rate_date:\n",
    "                    # Create a new row for the participant and date\n",
    "                    new_row = [participant_identifier, resting_heart_rate_date, resting_heart_rate, None, None]\n",
    "\n",
    "                    # Add the new row to the aggregate_data list\n",
    "                    aggregate_data.append(new_row)\n",
    "\n",
    "            # Search for daily steps CSV\n",
    "            daily_steps_file = [file for file in os.listdir(data_directory) if\n",
    "                                file.startswith(\"HealthKitV2Statistics_DailySteps_\") and file.endswith(\".csv\")]\n",
    "            if daily_steps_file:\n",
    "                daily_steps_file = os.path.join(data_directory, daily_steps_file[0])\n",
    "                with open(daily_steps_file, \"r\") as daily_steps_csv:\n",
    "                    daily_steps_reader = csv.reader(daily_steps_csv)\n",
    "                    next(daily_steps_reader)  # Skip the header row\n",
    "\n",
    "                    # Continue with the remaining steps of the code\n",
    "\n",
    "                    daily_steps_date= None\n",
    "                    daily_steps= None\n",
    "                    for steps_row in daily_steps_reader:\n",
    "                        if steps_row[1] == participant_identifier:\n",
    "                            daily_steps = steps_row[4]\n",
    "                            daily_steps_date = steps_row[3].split(\"T\")[0]  # Extract the date portion\n",
    "                            break\n",
    "\n",
    "                \n",
    "                # Check if daily steps data is found\n",
    "                if daily_steps_date:\n",
    "                    # Create a new row for the participant and date\n",
    "                    new_row = [participant_identifier, daily_steps_date, None, daily_steps, None]\n",
    "                    # Add the new row to the aggregate_data list\n",
    "                    aggregate_data.append(new_row)\n",
    "\n",
    "                \n",
    "\n",
    "       \n",
    "        elif device_type.startswith(\"Fitbit\"):\n",
    "            # Search for Fitbit daily data CSV\n",
    "            fitbit_data_file = [file for file in os.listdir(data_directory) if\n",
    "                                file.startswith(\"FitbitDailyData\") and file.endswith(\".csv\")]\n",
    "            if fitbit_data_file:\n",
    "                fitbit_data_file = os.path.join(data_directory, fitbit_data_file[0])\n",
    "                with open(fitbit_data_file, \"r\") as fitbit_data_csv:\n",
    "                    fitbit_data_reader = csv.reader(fitbit_data_csv)\n",
    "                    next(fitbit_data_reader)  # Skip the header row\n",
    "                    for fitbit_row in fitbit_data_reader:\n",
    "                        if fitbit_row[0] == participant_identifier:\n",
    "                            fitbit_date = fitbit_row[1].split(\"T\")[0]  # Extract the date portion\n",
    "                            steps = fitbit_row[40]\n",
    "                            resting_heart_rate = fitbit_row[39]\n",
    "\n",
    "                            # Update the corresponding date's row in the aggregate_data list\n",
    "                            for data_row in aggregate_data:\n",
    "                                if data_row[0] == participant_identifier and data_row[1] == fitbit_date:\n",
    "                                    data_row[2] = str(int(data_row[2]) + int(resting_heart_rate))\n",
    "                                    data_row[3] = str(int(data_row[3]) + int(steps))\n",
    "                                    break\n",
    "                            else:\n",
    "                                # Create a new row for the participant and date\n",
    "                                new_row = [participant_identifier, fitbit_date, resting_heart_rate, steps, None]\n",
    "                                aggregate_data.append(new_row)\n",
    "\n",
    "            # Search for Fitbit sleep logs CSV\n",
    "            fitbit_sleep_file = [file for file in os.listdir(data_directory) if\n",
    "                                  file.startswith(\"FitbitSleepLogs\") and file.endswith(\".csv\")]\n",
    "            if fitbit_sleep_file:\n",
    "                fitbit_sleep_file = os.path.join(data_directory, fitbit_sleep_file[0])\n",
    "                with open(fitbit_sleep_file, \"r\") as fitbit_sleep_csv:\n",
    "                    fitbit_sleep_reader = csv.reader(fitbit_sleep_csv)\n",
    "                    next(fitbit_sleep_reader)  # Skip the header row\n",
    "                    for sleep_row in fitbit_sleep_reader:\n",
    "                        if sleep_row[0] == participant_identifier:\n",
    "                            sleep_date = sleep_row[2].split(\"T\")[0]  # Extract the date portion\n",
    "                            sleep_duration = int(sleep_row[7]) / 60  # Convert minutes to hours\n",
    "\n",
    "                            # Update the corresponding date's row in the aggregate_data list\n",
    "                            for data_row in aggregate_data:\n",
    "                                if data_row[0] == participant_identifier and data_row[1] == sleep_date:\n",
    "                                    data_row[4] = str(sleep_duration)\n",
    "                                    break\n",
    "                            else:\n",
    "                                # Create a new row for the participant and date\n",
    "                                new_row = [participant_identifier, sleep_date, None, None, str(sleep_duration)]\n",
    "                                aggregate_data.append(new_row)\n",
    "                                break\n",
    "\n",
    "        elif device_type.startswith(\"Garmin\"):\n",
    "            # Search for Garmin daily summary CSV files\n",
    "            garmin_summary_files = [file for file in os.listdir(data_directory) if\n",
    "                                    file.startswith(\"GarminDailySummary_\") and \"samples\" not in file]\n",
    "            for garmin_summary_file in garmin_summary_files:\n",
    "                garmin_summary_file = os.path.join(data_directory, garmin_summary_file)\n",
    "                with open(garmin_summary_file, \"r\") as garmin_summary_csv:\n",
    "                    garmin_summary_reader = csv.reader(garmin_summary_csv)\n",
    "                    next(garmin_summary_reader)  # Skip the header row\n",
    "                    for garmin_row in garmin_summary_reader:\n",
    "                        if garmin_row[1] == participant_identifier:\n",
    "                            garmin_date = garmin_row[6].split(\"T\")[0]  # Extract the date portion\n",
    "                            resting_heart_rate = garmin_row[18]\n",
    "                            steps = garmin_row[9]\n",
    "\n",
    "                            # Update the corresponding date's row in the aggregate_data list\n",
    "                            for data_row in aggregate_data:\n",
    "                                if data_row[0] == participant_identifier and data_row[1] == garmin_date:\n",
    "                                    data_row[2] = str(int(data_row[2] or 0) + int(resting_heart_rate or 0))\n",
    "                                    data_row[3] = str(int(data_row[3] or 0) + int(steps or 0))\n",
    "                                    #break\n",
    "                            else:\n",
    "                                # Create a new row for the participant and date\n",
    "                                new_row = [participant_identifier, garmin_date, resting_heart_rate, steps, None]\n",
    "                                aggregate_data.append(new_row)\n",
    "\n",
    "                            # Search for Garmin sleep summary CSV\n",
    "                            garmin_sleep_files = [file for file in os.listdir(data_directory) if\n",
    "                                                  file.startswith(\"GarminSleepSummary_\") and file.endswith(\".csv\")]\n",
    "                            for garmin_sleep_file in garmin_sleep_files:\n",
    "                                garmin_sleep_file = os.path.join(data_directory, garmin_sleep_file)\n",
    "                                with open(garmin_sleep_file, \"r\") as garmin_sleep_csv:\n",
    "                                    garmin_sleep_reader = csv.reader(garmin_sleep_csv)\n",
    "                                    next(garmin_sleep_reader)  # Skip the header row\n",
    "                                    for sleep_row in garmin_sleep_reader:\n",
    "                                        if sleep_row[1] == participant_identifier:\n",
    "                                            sleep_date = sleep_row[6].split(\"T\")[0]  # Extract the date portion\n",
    "                                            sleep_duration = int(sleep_row[5]) / 60 / 60  # Convert seconds to hours\n",
    "\n",
    "                                            # Update the corresponding date's row in the aggregate_data list\n",
    "                                            for data_row in aggregate_data:\n",
    "                                                if data_row[0] == participant_identifier and data_row[1] == sleep_date:\n",
    "                                                    data_row[4] = str(sleep_duration)\n",
    "                                                    break\n",
    "                                            else:\n",
    "                                                # Create a new row for the participant and date\n",
    "                                                new_row = [participant_identifier, sleep_date, None, None, str(sleep_duration)]\n",
    "                                                aggregate_data.append(new_row)\n",
    "                                                break\n",
    "\n",
    "# Sort the aggregate_data list by date\n",
    "aggregate_data.sort(key=lambda x: x[1])\n",
    "\n",
    "# Print the extracted data\n",
    "for data_row in aggregate_data:\n",
    "    print(data_row)\n",
    "\n",
    "# Write the aggregate data to the output CSV file\n",
    "with open(output_file, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(columns)\n",
    "    writer.writerows(aggregate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
